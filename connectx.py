# -*- coding: utf-8 -*-
"""ConnectX.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PkhQuMrr6D7I0Ya5JnRQrhxXRpguz2v2

# ConnectX Auto Player

## Install Kaggle-environments
"""

# !pip install kaggle-environments

import kaggle_environments as ke
import numpy as np
import random
import pickle

def make_environment():
  env = ke.make('connectx', debug=True)
  return env

class Agent:
  def __init__(self, ncols, nrows, min_exploration_rate, max_exploration_rate, exploration_decay_rate, learning_rate, discount_rate, q_table={}):
    self.q_table = q_table
    self.ncols = ncols
    self.nrows = nrows
    self.valid_actions = np.array(range(ncols))
    self.valid_actions_copy = []
    self.temp_q_values = []
    self.exploration_rate = max_exploration_rate
    self.max_exploration_rate = max_exploration_rate
    self.min_exploration_rate = min_exploration_rate
    self.exploration_decay_rate = exploration_decay_rate
    self.learning_rate = learning_rate
    self.discount_rate = discount_rate

  def reset_valid_actions(self):
    self.valid_actions = np.array(range(self.ncols))

  # Updates valid actions based on the given board
  def update_valid_actions(self, board):
    self.valid_actions_copy = self.valid_actions.copy()
    for col in self.valid_actions_copy:
      if board[col] != 0:
        self.valid_actions = np.delete(self.valid_actions, np.argwhere(self.valid_actions == col))

  # Generate dict key
  def to_str(self, board):
    return ' '.join([str(elem) for elem in board])

  def sample(self):
    return np.random.choice(self.valid_actions).item()

  def greedy(self, board):
    # Set invalid action values as -inf
    self.temp_q_values = self.q_table[self.to_str(board)].copy()
    for col in range(self.ncols):
      if col not in self.valid_actions:
        self.temp_q_values[col] = float('-inf')

    return np.argmax(self.temp_q_values).item()

  # Generate action for the given board
  def action(self, board):
    self.update_valid_actions(board)

    if self.q_table.get(self.to_str(board)) is None:
      self.q_table[self.to_str(board)] = np.zeros((self.ncols, ))
      return self.sample()

    exploration_rate_threshold = random.uniform(0, 1)
    if exploration_rate_threshold > self.exploration_rate:
        return self.greedy(board)
    else:
        return self.sample()

  # Generate THE BEST action for the given board
  def play(self, obs, config):
    board = obs['board']

    self.update_valid_actions(board)

    if self.q_table.get(self.to_str(board)) is None:
      self.q_table[self.to_str(board)] = np.zeros((self.ncols, ))
      return self.sample()

    return self.greedy(board)

  def update_exploration_rate(self, episode):
    self.exploration_rate = self.min_exploration_rate + (self.max_exploration_rate - self.min_exploration_rate) * np.exp(-self.exploration_decay_rate * episode)

  def update_q_table(self, board, reward, action, old_board):
    str_old_board = self.to_str(old_board)
    str_board = self.to_str(board)

    if reward is None:
      reward = 0

    a = self.learning_rate * (reward + self.discount_rate * np.max(self.q_table[str_board] if str_board in self.q_table else np.array([0])))

    self.q_table[str_old_board][action] = self.q_table[str_old_board][action] * (1 - self.learning_rate) + a

  def save_q_table(self, filename):
    outfile = open(filename,'wb')
    pickle.dump(self.q_table, outfile)
    outfile.close()

  def load_q_table(self, filename):
    try:
      infile = open(filename,'rb')
      self.q_table = pickle.load(infile)
      infile.close()
    except:
      print("Not able to load Q Table.")
